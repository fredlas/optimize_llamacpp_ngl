# optimize_llamacpp_ngl
empirically chooses -ngl param for llama.cpp
